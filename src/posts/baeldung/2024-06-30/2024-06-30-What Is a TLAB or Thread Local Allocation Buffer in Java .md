---
date: 2023-09-01
category:
  - Java
  - JVM
tag:
  - TLAB
  - 内存分配
head:
  - - meta
    - name: keywords
      content: Java, JVM, TLAB, 内存分配, 性能优化
---
# Java中的TLAB或线程本地分配缓冲区是什么？

在本教程中，我们将探讨线程本地分配缓冲区（TLABs）。我们将了解它们是什么，JVM如何使用它们，以及我们如何管理它们。

## Java中的内存分配

Java中的某些命令将分配内存。最明显的是_new_关键字，但还有其他的——例如，使用反射。

每当我们这样做时，JVM必须在堆上为新对象留出一些内存。特别是，JVM内存分配以这种方式在Eden或Young空间中进行所有分配。

在单线程应用程序中，这很容易。由于一次只能发生一个内存分配请求，线程可以简单地获取下一个合适大小的块，我们完成了：

![img](https://www.baeldung.com/wp-content/uploads/2023/09/single-threaded-heap-allocation-1024x307.png)

然而，在多线程应用程序中，我们不能这么简单地做事。如果我们这样做，那么两个线程将同时请求内存并都被赋予完全相同的块的风险：

![img](https://www.baeldung.com/wp-content/uploads/2023/09/multithreaded-heap-allocation-1024x456.png)

为了避免这种情况，我们同步内存分配，使得两个线程不能同时请求相同的内存块。然而，同步所有内存分配将使它们本质上变成单线程，这可能是我们应用程序中的一个巨大瓶颈。

## 线程本地分配缓冲区

JVM使用线程本地分配缓冲区，或TLABs，来解决这个问题。这些是为给定线程保留的堆内存区域，并且只由该线程用于分配内存：

![img](https://www.baeldung.com/wp-content/uploads/2023/09/tlab-heap-allocation-1024x564.png)

通过这种方式工作，不需要同步，因为只有一个线程可以从这个缓冲区中拉取。缓冲区本身是以同步方式分配的，但这是一个不那么频繁的操作。

由于为对象分配内存是一个相对常见的事件，这可能是一个巨大的性能提升。但究竟有多大的提升呢？我们可以通过一个简单的测试来容易地确定这一点：

```java
@Test
public void testAllocations() {
    long start = System.currentTimeMillis();

    List`<Object>` objects = new ArrayList<>();
    
    for (int i = 0; i < 1_000_000; ++i) {
        objects.add(new Object());
    }
    
    Assertions.assertEquals(1_000_000, objects.size());

    long end = System.currentTimeMillis();
    System.out.println((end - start) + "ms");
}
```

这是一个相对简单的测试，但它能完成工作。我们将为1,000,000个新的_Object_实例分配内存，并记录所需的时间。然后我们可以多次运行这个测试，同时开启和关闭TLAB，并看看平均时间是多少（我们将在第5节中看到如何关闭TLAB）：

![img](https://www.baeldung.com/wp-content/uploads/2023/09/TLAB-Timings.png)

我们可以清楚地看到差异。使用TLAB的平均时间是33毫秒，而不使用时上升到110毫秒。这只是通过改变这一个设置，就增加了230%。

### 3.1. TLAB空间耗尽

显然，我们的TLAB空间是有限的。那么，当我们用完TLAB空间时会发生什么呢？

如果我们的应用程序尝试为新对象分配空间，而TLAB没有足够的可用空间，JVM有四种可能的选择：

1. 它可以为这个线程分配新的TLAB空间量，有效地增加可用的数量。
2. 它可以在TLAB空间之外为这个对象分配内存。
3. 它可以试图使用垃圾收集器释放一些内存。
4. 它可以无法分配内存，而是抛出一个错误。

**选项#4是我们的灾难性情况，所以我们要尽可能避免**，但如果其他情况不能发生，它是一个选项。

JVM使用一些复杂的启发式方法来决定使用哪种其他选项，这些启发式方法可能在不同的JVM和不同版本之间会有所变化。然而，**最重要的细节包括**：

- 在一段时间内可能进行的分配数量。如果我们很可能分配很多对象，那么增加TLAB空间将是一个更有效的选择。如果我们很可能分配非常少的对象，那么增加TLAB空间实际上可能效率更低。
- 正在请求的内存量。请求的内存越多，在TLAB空间之外分配这个内存的成本就越高。
- 可用的内存量。如果JVM有很多可用的内存，那么增加TLAB空间比内存使用非常高时要容易得多。
- 内存争用量。如果JVM有很多线程，每个线程都需要内存，那么增加TLAB空间可能比只有很少线程时要贵得多。

### 3.2. TLAB容量

**使用TLAB似乎是提高性能的绝佳方式，但总有成本。**防止多个线程分配相同内存区域所需的同步使得TLAB本身相对昂贵。如果JVM的内存使用特别高，我们可能还需要等待足够的内存可供分配。

然而，如果一个线程为其TLAB空间分配了比它需要的更多的内存，那么这个内存就会闲置在那里，基本上是浪费的。更糟糕的是，浪费这个空间使得其他线程更难获得TLAB空间的内存，可能会使整个应用程序变慢。

因此，关于要分配多少空间存在争议。分配太多，我们就是在浪费空间。但分配太少，我们将花费比理想中更多的时间来分配TLAB空间。

幸运的是，JVM会为我们处理所有这些，尽管我们将很快看到如何根据需要调整它。

## 4. 查看TLAB使用情况

**现在我们知道了TLAB是什么以及它对我们的应用程序可能产生的影响，我们如何在实际操作中看到它呢？**

不幸的是，_jconsole_工具并没有像它对标准内存池那样提供对它的可见性。

然而，JVM本身可以输出一些诊断信息。这使用了新的统一GC日志记录机制，所以我们必须**使用-Xlog:gc+tlab=trace标志启动JVM**以查看这些信息。然后，它将定期打印出有关JVM当前TLAB使用情况的信息。例如，在GC运行期间，我们可能会看到类似的东西：

```shell
[0.343s][trace][gc,tlab] GC(0) TLAB: gc thread: 0x000000014000a600 [id: 10499] desired_size: 450KB slow allocs: 4  refill waste: 7208B alloc: 0.99999    22528KB refills: 42 waste  1.4% gc: 161384B slow: 59152B
```

这告诉我们，对于这个特定的线程：

- 当前的TLAB大小是450KB（_desired_size_）。
- 自上次GV以来，有四次在TLAB之外的分配（_slow allocs_）。

请注意，确切的日志记录会在JVM和版本之间有所不同。

## 5. 调整TLAB设置

**我们已经看到了开启和关闭TLAB的影响，但我们还能做些什么呢？我们可以通过在启动应用程序时提供JVM参数来调整许多设置。**

首先，让我们看看如何关闭它。这是通过传递JVM参数-XX:-UseTLAB完成的。设置这个将停止JVM使用TLAB，并强制它在每次内存分配上使用同步。

我们也可以保留TLAB启用状态，但通过设置JVM参数-XX:-ResizeTLAB来阻止它调整大小。这样做意味着如果给定线程的TLAB填满了，所有未来的分配都将在TLAB之外进行，并需要同步。

我们还可以通过提供JVM参数-XX:TLABSize来配置TLAB的大小。这定义了JVM应该为每个TLAB使用的推荐初始大小，因此它是每个线程分配的大小。如果这被设置为0——这是默认值——那么JVM将根据JVM的当前状态动态决定每个线程分配多少。

我们还可以指定-XX:MinTLABSize，以给出每个线程的TLAB大小的下限，以防我们允许JVM动态确定大。我们还有-XX:MaxTLABSize作为每个线程的TLAB可以增长的上限。

**所有这些设置都有合理的默认值，通常最好只使用这些默认值，但如果我们发现有问题，我们确实有一定的控制水平。**

## 6. 总结

**在本文中，我们已经看到了线程本地分配缓冲区是什么，它们是如何使用的，以及我们如何管理它们。**下次当你的应用程序遇到任何性能问题时，考虑这可能是值得调查的事情。